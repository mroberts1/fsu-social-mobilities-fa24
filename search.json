[
  {
    "objectID": "custom_callouts.html",
    "href": "custom_callouts.html",
    "title": "Custom Callouts",
    "section": "",
    "text": "This is my test solution\n\n\nAnd some content inside of it"
  },
  {
    "objectID": "custom_callouts.html#quarto",
    "href": "custom_callouts.html#quarto",
    "title": "Custom Callouts",
    "section": "Quarto",
    "text": "Quarto\nQuarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "custom_callouts.html#running-code",
    "href": "custom_callouts.html#running-code",
    "title": "Custom Callouts",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  },
  {
    "objectID": "header.html",
    "href": "header.html",
    "title": "Home",
    "section": "",
    "text": "Fitchburg State University\nCommunications Media Department\nMS in Applied Communication: Social Media Concentration\nGCE Online-Accelerated\nTues 29 October—Tues 17 December 2024\nMartin Roberts\n  |  |  |"
  },
  {
    "objectID": "w2-algorithm.html",
    "href": "w2-algorithm.html",
    "title": "Home",
    "section": "",
    "text": "Kyle Chayka, “How The Internet Turned Us Into Content Machines” (New Yorker, 4 June 2022)",
    "crumbs": [
      "Agendas",
      "W2 Algorithm"
    ]
  },
  {
    "objectID": "w2-algorithm.html#w2-algorithm",
    "href": "w2-algorithm.html#w2-algorithm",
    "title": "Home",
    "section": "W2: Algorithm",
    "text": "W2: Algorithm\nKyle Chayka, Filterworld: How Algorithms Flattened Culture“Introduction” “The Rise of Algorithmic Recommendations” (ch. 1) See also: “The Banality of Online Recommendation Culture” (New Yorker, 30 October 2024)\nIt can be safely assumed that, for better or worse, in light of the events of the past twenty-four hours the Algorithm is probably the last thing one anyone’s mind right now! Nevertheless, I’m going to black-box the election and its aftermath here and stay focused on the topic at hand: the opening two chapters of Kyle Chayka’s recent book on algorithmic culture, Filterworld.\nThe chapters themselves are so packed with insights and references to other research sources that I’m not going to add to them here; I’m more interested in hearing your own collective response to them and discussing it with you in the coming week. Instead, I’ll limit myself here to connecting you to some of the sources on which Chayka’s own book is based, which provide an ideal starting point for anyone interested in exploring the subject for your research project later in the course.\nAs with Kate Eichhorn’s book about content or any of the other texts that we’re going to be dipping into in upcoming weeks, you might also be interested in continuing with the book and writing a review of it for the Book Report assignment due at the end of Week 5.\nThe first chapter of Filterworld is essentially the extended of mix of several articles that Chayka published as articles on his Substack blog and subsequently in The New Yorker (subscription required) in 2022. The Substack article in particular is worth taking a closer look at because it references a survey that Chayka conducted about algorithmic recommendation systems that received 125 responses. I thought it might be interesting to assign our group to answer some of the questions asked in the survey as a starting point for our discussion.\nHere are the main five questions, after those requesting name and contact information. Since chapter 1 of Filterworld provides a definition of the term algorithm itself, I’ve also skipped that one here:\n\n\n\n\nHas “the algorithm,” or algorithmic feeds, taken up more of your online experience over the years? What has that change felt like?\nDo the algorithms of different platforms / feeds feel very different? Like TikTok vs Instagram, FB vs Twitter, Netflix vs Spotify…\nHave you had any particularly odd run-ins with algorithms or automated recommendations? Maybe it’s eerily accurate Instagram ads (or terrible ones), getting served the same content as a friend, missing a Netflix show, or someone surprising popping up in your feed… Describe anything that comes to mind.\nIf you are a creator (artist, musician, writer, YouTuber, whatever), do you ever feel pressure to mold your work in a certain way to fit with an algorithmic feed / platform? What is that pressure like?\nDo you have any hacks / theories as to what makes a piece of content succeed in an algorithmic feed? Any tricks that you use or have used when you just want something to get attention?\n\n\n\n\nYou don’t have to answer all of these questions, but for your Review response this week, feel free to select one or two of them if you’d like to respond. If it brings anything to mind, the third question, about random or odd recommendations, might be the most interesting one of the set.\nI’m guessing that the section of Chayka’s first chapter (not the Introduction, the second, longer chapter) that you found most interesting is about the concept of algorithmic anxiety, a term that as he explains was used by Kate Crawford in 2013, was developed in Patricia De Vries’s blog (well worth checking out!) for the Institute of Network Cultures website, and was the subject a 2018 academic paper about AirBnB.De Vries herself subsequently explored the subject in her pathbreaking study Algorithmic Anxiety in Contemporary Art (University of Amsterdam, 2020), available as an open-source publication from the Institute’s website.\nAs Chayka explains, De Vries’s book emerged from her research on contemporary digital artists whose work focuses on surveillance and resistance to this, notably Jill Magid and Trevor Paglen. For a survey of contemporary internet art that includes chaptes on both of these artists, see Lauren Cornell and Ed Halter’s anthology, Mass Effect: Art and the Internet in the Twenty-First Century (Cambridge ,MA: MIT Press, 2015).\n\n\n \nDe Vries has a number of interesting presentations about internet art and algorithmic culture on YouTube - I’ve created a playlist for the course and have added them to it, and encourage you to take a look. I’ll be adding more YouTube sources to the playlist as the course progresses, so add it to your bookmarks toolbar.\nOne other source mentioned in Chayka’s chapter on algorithmic recommendations is Taylor Lorenz’s Washington Post article about the concept of algospeak, which I’m also linking to here.Taylor Lorenz, “Internet ‘algospeak’ is changing our language in real time, from ‘nip nops’ to ‘le dollar bean’” (Washington Post, 8 April 2022).\nTaylor Lorenz is also the author of another interesting recent book about contemporary internet culture.\n\n\n\nExtremely Online: The Untold Story of Fame, Influence, and Power on the Internet (New York: Simon & Schuster, 2023).\nWell that should keep you busy for a week or two! Look forward to discussing the Filterworld chapters and any other of the above sources with you in the coming week!",
    "crumbs": [
      "Agendas",
      "W2 Algorithm"
    ]
  },
  {
    "objectID": "w1-content.html",
    "href": "w1-content.html",
    "title": "Home",
    "section": "",
    "text": "Kate Eichhorn, Content:\n\n“A Brief History of Content in a Digital Era”\n“User-Generated Content” (recommended)\n\n\n\n\nSee also: Patrick H. Willems, “Everything is Content Now” (YouTube)",
    "crumbs": [
      "Agendas",
      "W1 Content"
    ]
  },
  {
    "objectID": "w1-content.html#w1-content",
    "href": "w1-content.html#w1-content",
    "title": "Home",
    "section": "",
    "text": "Kate Eichhorn, Content:\n\n“A Brief History of Content in a Digital Era”\n“User-Generated Content” (recommended)\n\n\n\n\nSee also: Patrick H. Willems, “Everything is Content Now” (YouTube)",
    "crumbs": [
      "Agendas",
      "W1 Content"
    ]
  },
  {
    "objectID": "w1-content.html#infinite-content",
    "href": "w1-content.html#infinite-content",
    "title": "Home",
    "section": "Infinite Content",
    "text": "Infinite Content\n\nWho doesn’t love Seinfeld, the classic sitcom show about nothing that was the benchmark for TV comedy in the 1990s? Now that all 9 seasons are streaming on Netflix, Gen Zers who are too young to have seen the show when it was first aired can enjoy it in all its glory. As anyone familiar with the show knows, the premise of the show itself was that it was a show “about nothing”—early in its history there was even a very “meta” series of episodes in which Jerry and George pitch their idea for a comedy “about nothing” to executives at NBC–the very network that was actually airing those episodes!\nWhich is why it’s strangely appropriate that the show is the reference-point for one of the stranger forms of “content” to have swum across my screen in recent years: a procedurally-generated, never-ending animated version of the show that began streaming on the Twitch gaming platform last year, titled—appropriately enough—Nothing, Forever.\nI mention this example for a number of reasons. First, because it’s a perfect example of the content category that Kate Eichhorn defines as entertainment content in the first chapter of her recent book on the subject. Back in the 1990s, Seinfeld was airing at the exact same time that Bill Gates first published his famous essay, “Content is King” (referenced in Patrick Willem’s YouTube video on the same subject). Yet as prescient as that essay may now seem in retrospect, the term “content” was still far from taking on the specific meaning that it began to about a decade later, while nobody at the time would have dreamed of describing Seinfeld as content: it was simply television. The distance between then and now is a measure of how far digital media and the emergence of the World Wide Web (as it was still called when Seinfeld was airing on NBC) have tranformed the nature of entertainment over the intervening quarter century. For in contrast to its 1990s TV source, Nothing, Forever is a quintessential example of what we mean today by the term content: a media text whose cultural value resides primarily—if not exclusively—in its capacity to circulate widely across the social mediascape. In that respect, Nothing, Forever can be seen as a counterpart to the Instagram egg account that provides the starting-point for Kate Eichhorn’s discussion of content. And like its counterpart, the Twitchstream show quickly began to propagate beyond the specific platform on which it originated. In addition to the torrent of online chatter it generated on tech news sites and social media platforms like Reddit, it quickly spawned the by now all-too-familiar YouTube spin-offs: a best-of compilation, a playlist of archived episodes, and numerous dystopian predictions by social media commentators of how the show was a harbinger of the imminent tidal wave of generative-AI content about to break over our heads.\n\nOther than the fact that it was animated rather than a live-action sitcom, this is, of course, the most significant difference between Nothing, Forever and its televisual source. Remediated on Netflix, the original collection of TV episodes that comprise the original Seinfeld series were transmuted into content: just another batch of archival TV shows on the shelf of the vast library of “classic” or “vintage” TV, not to mention all of the comedy series since. This reductive “flattening” of content, in which one show becomes functionally no different from any other is, as Patrick Willems explains in his YouTube video, one of the most insidious aspects of the concept of content in itself, and the basis for his critique of it.\nBut of course, Nothing, Forever is not just content in the same way that Seinfeld itself becomes content in the age of streaming media: it’s particular distinctive quality is that it’s also generative content, or more specifically that it’s procedurally generated sourced from the raw materials of the original show itself. This generative automation of its content is both continuous and—at least in principle— interminable, in that content can be algorithmically generated in this way ad infinitum: unlike its network-TV-era source, unlike even its on-demand streaming remediation, Nothing Forever was an early example of a new development in popular entertainment in the age of AI: infinite content. Rather than the gnarly animated visuals and stilted dialogue, it’s this generative dimension of the show that cultural critics seemed to find most disturbing: that as the title made clear, it could go on forever. What dire implications did this have for the actually-existing, still human-based entertainment industry? Could it be seen as a sign of the beginning of the end of that industry in itself? Certainly there have been no shortage of media commentators to have claimed that this is precisely the threat posed by AI-generated content to the creative industries in general. My own view is that the backlash against AI that has quickly taken hold in the entertainment industry over the past year or two—as seen in the recent industrial action of the writers’ and actors’ guilds–may prove to have over-stated the doomsday scenarios that have been circulating. I’d be interested to hear your thoughts on that issue!\nSpeculations about the future of the content industry aside, what is clear in the present is that generative content of the type exemplified by Nothing, Forever currently represents the leading edge of creative experimentation with algorithmic technologies. But the tsunami of AI-generated entertainment has already begun to break, most notably on YouTube itself, which currently hosts a rapidly-growing corpus of AI-generated movies using contemporary neural networks (aka “large-language models” or LLMs) like Runway, Sora, ComfyUI, and many more. (This topic is also explored by Kate Eichhorn in the concluding chapter of her book.)\nLet me conclude with what may seem like a counter-intuitively positive pointt about generative entertainment content. In the midst of the current and ongoing furore about the onset of what might be called the age of procedural media aspect has been overlooked: its social role as a catalyst for generating new forms of creative community. One interesting element of the Twitchstream version of Nothing, Forever was that it was accompanied by a live-feed chat of people talking about and responding to the show in real time. Significantly, no such real-time chat was available on Netflix for streaming re-runs of the original Seinfeld series. Nothing, Forever also sparked intense discussion on Reddit in the generative sub-group, as well as elsewhere across the social mediascape.\nIn the end, old-school media studies questions about audience, and whether anyone was actually watching Nothing, Forever the way TV audiences back in the 1990s had gathered to watch Seinfeld when it aired, are moot. The Twitch show simply belongs to a very different media species, in which the primary purpose of content–whether generative or otherwise—is catalytic, serving not just to circulate but to generate social interaction and community. If you look around online, you will see many examples of such content. Contrary to what is often assumed, this content is highly effective in generating further chains of content—memes are a good example.\nSo in conclusion, I would suggest that in addition to the categories of content defined by Kate Eichhorn in the first chapter of her book—Marketing Content, Entertainment Content, Educational Content, User-Generated Content, etc.–we may add a further one: Meta-Content. Meta-Content is content where the buzz or discourse around a particular kind of content is at least as significant as the source content that produced it. From that perspective the “buzz” around Nothing, Forever was as much a part of its content as the actual show itself. In a way, when it comes to Meta-Content the nature of the content “itself” is almost arbitrary—it doesn’t matter all that much what it is, as long as it captures people’s attention and spawns larger conversations—or better still, controversies. If this hypothesis is correct, it’s all the more interesting—and ironic—that the show that may be remembered as one of the inaugural examples of generative content is a show about nothing. While there may be nothing–or at most hardly anything–to watch, there is certainly plenty to talk about, and in the age of Meta-Content, that is all that matters.\nI’ll leave you with one last example of another new form of (Meta-)content that has also begun to emerge from the media laboratory known as YouTube: satirical commentary on AI creativity itself. You may enjoy this amusing reflection on the possible future into which we may be heading, and the strange new kinds of creative practices that may emerge from it.",
    "crumbs": [
      "Agendas",
      "W1 Content"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "This seminar is an exploration of what it means to live with personal, portable, and handheld media technologies. We will study these technologies across time and space by situating them within their historical contexts and by studying their use in various settings. We’ll also employ a variety of theoretical frameworks and interdisciplinary approaches. Simultaneously, we will attempt to analyze and theorize our own handheld media experiences through and against the course readings.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy the end of the course, students will be able to:\n\nanalyze technologies past, present, and imagined\ndescribe the ways in which technologies shape our world the ways in which we shape those technologies\nexplain how social media is a result of the intersection between technologies and existing human communication dynamics\ndiscuss how theory of technology and social media can improve the vocational outlook of a student\nplay a productive role in and facilitate conversations that tease out the relationships between values and technology.\nthrough the skills you will refine in writing your research papers, clearly explain how a specific technology shapes the social world that we live in.\n\n\n\n\nAvailable as audiobooks (Audible) and ebooks (Kindle), as well as print.\nKyle Chayka, Filterworld: How Algorithms Flattened Culture. New York: Doubleday, 2024.\nKate Eichhorn, Content. Essential Knowledge Series. Cambridge, MA: MIT Press, 2022.\nParmy Olson, Supremacy: AI, ChatGPT, and the Race that Will Change the World. New York: MacMillan, 2024.\nChristine Lagorio-Chafkin, We Are the Nerds: The Birth and Tumultuous Life of Reddit, the Internet’s Culture Laboratory. New York: Hachette Books, 2018.\nAllissa V. Richardson, Bearing Witness While Black: African Americans, Smartphones, and the New Protest #Journalism. Oxford: Oxford University Press, 2020.\nStefania Maurizi, Secret Power: Wikileaks and Its Enemies. Pluto Press, 2023.\n\n\n\nCitizenfour (2014)\nRisk (2016)\nSuper Pumped: The Battle for Uber (Showtime, 2022)\nWe Are Legion: The Story of the Hacktivists (2012)\nWeWork: Or the Making and Breaking of a $47 Billion Unicorn (Hulu, 2021)\nWikileaks: Secrets and Lies (2011)\n\n\n\n\n\n\nPlatforms\nWe’ll be using Blackboard for submitting assignments ONLY. For discussion, we will be using Discord.\nOn Discord, if you don’t already have an account, please set one up using your Fitchburg State University email address as ID.\nIf you already have a Discord account there will be problems setting up an account for the course because each account has to be tied to a different phone number, so you will not be able to use your regular phone number for verification. For this reason, you may use your existing account, but if you use a pseudonym please let me know what this is so I know who you are!\nPlease be sure to check in to the site at least once daily M-F to check the Announcements page and the Discussion forum for the week.\n\n\n\n\nReview\n6, weekly from Week 1, one short post responding to readings, 250 words (maximum), due by Sunday of each week (20%)\nDiscord\nRegular participation in weekly discussion and other channels (20%)\nCommentary papers\n2 short analysis papers (500 words, 2 pages double-spaced) based on any of the reading assignments, due on Blackboard by end of Weeks 2 and 4 (Sunday) (20%)\nBook Report\nCritical review (1,000 words, 4 pages double-spaced) of any text from the select bibliography. You are expected to read at least one additional chapter from any of the main course books. For texts scheduled in weeks 5-6, you’ll need to read ahead. Due on Blackboard by Friday of Week 5 (20%)\nResearch paper/report/creative project  2,000 words, due on Blackboard by Friday of Week 7 (20%)\nThe culminating written assignment for the course (2,000 words) may consist of various formats: a research paper or report, or a creative project (blog, website, podcast)\nA 1-page tentative proposal with ideas for your project, with a short bibliography with sources and/or links, should be posted in the Discussion forum on Blackboard by the end of Week 3, and you will receive feedback during Week 4.\n\nBy Wednesday of each week, I will post an Agenda item in the Discussion forum for the topic of the week, that introduces and contextualizes the reading assignments for the week, identifying key themes, concepts, and/or issues to look out for as you read.\nCommentary Papers\nThese short papers (750-1,000 words) are due at the end of Week 2 and Week 4 (Sunday). They should consist of analytical close readings of any of the reading assignments for the period Weeks 1-2 or 3-4. You are encouraged to focus in detail on particular sections, arguments, and/or concepts from the readings and develop them.\nResearch Paper/Project\nThe culminating written assignment for the course (2,000 words) may consist of various formats: a research paper or report, or a creative project of your choice.\nA 1-page preliminary proposal with ideas for your project, with a short bibliography with sources and/or links, should be posted in the Discussion forum for the purpose by the end of Week 3, and you will receive feedback during Week 4.\n\n\n\n\nWeek 1: Tuesday 29 October 2024\nContent\nKate Eichhorn, Content:\n\n“A Brief History of Content in a Digital Era”\n“User-Generated Content” (recommended)\n\nSee also: Patrick H. Willems, “Everything is Content Now” (YouTube)\n\nWeek 2: Tuesday 5 November 2024\nAlgorithm\nKyle Chayka, Filterworld: How Algorithms Flattened Culture\n\n“Introduction”\n“The Rise of Algorithmic Recommendations” (ch. 1)\n\n\nWeek 3: Tuesday 12 November 2024\nChatbot\nParmy Olson, Supremacy: How the Struggle Between Google and Facebook Shapes Our Future\n\n“Prologue”\n“Mythbusters” (ch. 12)\n“Hello, ChatGPT” (ch. 13)\n\n\nWeek 4: Tuesday 19 November 2024\nNerd\nChristine Lagorio-Chafkin, We Are the Nerds: The Birth and Tumultuous Life of Reddit, the Internet’s Culture Laboratory\n\nWeek 5: Tuesday 26 November 2024\nWitness\nAllissa V. Richardson, Bearing Witness While Black\n\nWeek 6: Tuesday 3 December 2024\nWhistleblower\nStefania Maurizi, Secret Power: Wikileaks and Its Enemies\n\nWeek 7: Tuesday 10 December 2024\nResearch projects\nTuesday 17 December 2024: Last day of classes\n\n\n\n\ndanah boyd, It’s Complicated: The Social Lives of Networked Teens (New Haven: Yale University Press, 2014).\nAmy Bruckman, Should You Believe Wikipedia? Online Communities and the Construction of Knowledge (Cambridge: Cambridge University Press, 2022).\nFinn Brunton and Helen Nissenbaum, Obfuscation: A User’s Guide for Privacy and Protest (Cambridge: MIT Press, 2016).\nKyle Chayka, Filterworld: How Algorithms Flattened Culture (New York: Doubleday, 2024).\nGabriella Coleman, Hacker, Hoaxer, Whistleblower, Spy: The Many Faces of Anonymous (London and New York: Verso, 2014).\nClaire Dederer, Monsters: A Fan’s Dilemma (New York: Alfred A. Knopf, 2023).\nKate Eichhorn, Content. Essential Knowledge Series (Cambridge, MA: MIT Press, 2022).\nGlenn Greenwald, No Place to Hide: Edward Snowden, the NSA, and the U.S. Surveillance State (New York: Metropolitan Books, 2014).\nAdrian Hon, You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All (New York: Basic Books, 2022).\nSarah J. Jackson, Moya Bailey, et al., #Hashtag Activism: Networks of Race and Gender Justice (Cambridge: MIT Press, 2020).\nChristine Lagorio-Chafkin, We Are the Nerds: The Birth and Tumultuous Life of Reddit, the Internet’s Culture Laboratory (New York: Hachette Books, 2018).\nTaylor Lorenz, Extremely Online: How the Internet Changed the Way We Live, Love, Work, and Play (New York: Simon & Schuster, 2022}.\nGary Marcus & Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust (New York: Pantheon Books, 2019).\nStefania Maurizi, Secret Power: Wikileaks and Its Enemies. Pluto Press, 2023.\nGretchen McCulloch, Because Internet: Understanding the New Rules of Language (Riverhead Books, 2019)\nAngela Nagle, Kill All Normies: Online Culture Wars From 4Chan and Tumblr to Trump and the Alt-Right (Alresford, Hampshire, UK: Zero Books, 2017).\nParmy Olson, Supremacy: AI, ChatGPT, and the Race that Will Change the World. New York: MacMillan, 2024.\nCathy O’Neil, with Stephen Baker, The Shame Machine: Who Profits in the New Age of Humiliation (New York: Crown/Random House, 2022).\nWhitney Phillips, This Is Why We Can’t Have Nice Things: Mapping the Relationship between Online Trolling and Mainstream Culture (Cambridge: MIT Press, 2015).\nWhitney Phillips and Ryan M. Milner, You Are Here: A Field Guide for Navigating Polarized Speech, Conspiracy Theories, and Our Polluted Media Landscape (Cambridge: MIT Press, 2021).\nAllissa V, Richardson, Bearing Witness While Black: African Americans, Smartphones, and the New Protest #Journalism (Oxford: Oxford University Press, 2020).\nZeynep Tufekci, Twitter and Tear Gas: The Power and Fragility of Networked Protes (New Haven: Yale University Press, 2017}.\nMichele White, Touch Screen Theory: Digital Devices and Feelings (Cambridge, MA: MIT Press, 2022).\nChristopher Wylie, Mindf**k: Cambridge Analytica and the Plot to Break America (New York: Random House, 2019).\n\n\n\n\nLate Policy\nAssignments that are late will lose 1/2 of a grade per day, beginning at the end of class and including weekends and holidays. This means that a paper, which would have received an A if it was on time, will receive a B+ the next day, B- for two days late, and so on. Time management, preparation for our meetings, and timely submission of your work comprise a significant dimension of your professionalism. As such, your work must be completed by the beginning of class on the day it is due. If you have a serious problem that makes punctual submission impossible, you must discuss this matter with me before the due date so that we can make alternative arrangements. Because you are given plenty of time to complete your work, and major due dates are given to you well in advance, last minute problems should not preclude handing in assignments on time.\nMandatory Reporter\nFitchburg State University is committed to providing a safe learning environment for all students that is free of all forms of discrimination and harassment. Please be aware all FSU faculty members are “mandatory reporters,” which means that if you tell me about a situation involving sexual harassment, sexual assault, dating violence, domestic violence, or stalking, I am legally required to share that information with the Title IX Coordinator. If you or someone you know has been impacted by sexual harassment, sexual assault, dating or domestic violence, or stalking, FSU has staff members trained to support you. If you or someone you know has been impacted by sexual harassment, sexual assault, dating or domestic violence, or stalking, please visit http://fitchburgstate.edu/titleix to access information about university support and resources.\nHealth\nHealth Services\nHours: Monday-Friday 8:30AM-5PM Location: Ground Level of Russell Towers (across from the entrance of Holmes Dining Hall) Phone: (978) 665-3643/3894\nCounseling Services\nThe Counseling Services Office offers a range of services including individual, couples and group counseling, crisis intervention, psychoeducational programming, outreach ALTERNATIVE ECOSYSTEMSs, and community referrals. Counseling services are confidential and are offered at no charge to all enrolled students. Staff at Counseling Services are also available for consultation to faculty, staff and students. Counseling Services is located in the Hammond, 3rd Floor, Room 317.\nFitchburg Anti-Violence Education (FAVE)\nFAVE collaborates with a number of community partners (e.g., YWCA Domestic Violence Services, Pathways for Change) to meet our training needs and to link survivors with community based resources. This site also features resources for help or information about dating violence, domestic violence, sexual assault and stalking. If you or someone you know is in an abusive relationship or has been a victim of sexual assault, there are many places to go for help. Many can be accessed 24 hours a day, seven days a week, 365 days a year. On campus, free and confidential support is provided at both Counseling Services and Health Services.\nCommunity Food Pantry Food insecurity is a growing issue and it certainly can affect student learning. The ability to have access to nutritious food is incredibly vital. The Falcon Bazaar, located in Hammond G 15, is stocked with food, basic necessities, and can provide meal swipes to support all Fitchburg State students experiencing food insecurity for a day or a semester.\nThe university continues to partner with Our Father’s House to support student needs and access to food and services. All Fitchburg State University students are welcome at the Our Father’s House Community Food Pantry. This Pantry is located at the Faith Christian Church at 40 Boutelle St., Fitchburg, MA and is open from 5-7pm. Each “household” may shop for nutritious food once per month by presenting a valid FSU ID.\nAcademic Integrity\nThe University “Academic Integrity” policy can be found online at http:// www.fitchburgstate.edu/offices-services-directory/office-of-student-conductmediation-education/academic-integrity/. Students are expected to do their own work. Plagiarism and cheating are inexcusable. Any instance of plagiarism or cheating will automatically result in a zero on the assignment and may be reported the Office of Student and Academic Life at the discretion of the instructor.\nPlagiarism includes, but is not limited to: - Using papers or work from another class. - Using another student’s paper or work from any class. - Copying work or a paper from the Internet. - The egregious lack of citing sources or documenting research.\nIf you’re not clear on what is or is not plagiarism, ASK. The BEST case scenario if caught is a zero on that assignment, and ignorance of what does or does not count is not an excuse. That being said, I’m a strong supporter of Fair Use doctrine. Just attribute what you use–and, again, ASK if there’s any doubt.\nAmericans With Disabilities Act (ADA)\nIf you need course adaptations or accommodations because of a disability, if you have emergency medical information to share with the instructor, or if you need special arrangements in case the building must be evacuated, please inform the faculty member as soon as possible.\nTechnology\nAt some point during the semester you will likely have a problem with technology. Your laptop will crash; your iPad battery will die; a recording you make will disappear; you will accidentally delete a file; the wireless will go down at a crucial time. These, however, are inevitabilities of life, not emergences. Technology problems are not excuses for unfinished or late work. Bad things may happen, but you can protect yourself by doing the following:\n\nPlan ahead: A deadline is the last minute to turn in material. You can start—and finish—early, particularly if challenging resources are required, or you know it will be time consuming to finish this project.\nSave work early and often: Think how much work you do in 10 minutes. I auto save every 2 minutes.\nMake regular backups of files in a different location: Between Box, Google Drive, Dropbox, and iCloud, you have ample places to store and backup your materials. Use them.\nSave drafts: When editing, set aside the original and work with a copy.\nPractice safe computing: On your personal devices, install and use software to control viruses and malware.\n\nGrading Policy\nGrading for the course will follow the FSU grading policy below:\n4.0: 95-100\n3.7: 92-94\n3.5: 89-91\n3.3: 86-88\n3.0: 83-85\n2.7: 80-82\n2.5: 77-79\n2.3: 74-76\n2.0: 71-73\n0.0: &lt; 70\nAcademic Resources\nWriting Center\nAcademic Policies\nDisability Services\nFitchburg State Alert system for emergencies, snow closures/delays, and faculty absences\nUniversity Career Services"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "This seminar is an exploration of what it means to live with personal, portable, and handheld media technologies. We will study these technologies across time and space by situating them within their historical contexts and by studying their use in various settings. We’ll also employ a variety of theoretical frameworks and interdisciplinary approaches. Simultaneously, we will attempt to analyze and theorize our own handheld media experiences through and against the course readings."
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "By the end of the course, students will be able to:\n\nanalyze technologies past, present, and imagined\ndescribe the ways in which technologies shape our world the ways in which we shape those technologies\nexplain how social media is a result of the intersection between technologies and existing human communication dynamics\ndiscuss how theory of technology and social media can improve the vocational outlook of a student\nplay a productive role in and facilitate conversations that tease out the relationships between values and technology.\nthrough the skills you will refine in writing your research papers, clearly explain how a specific technology shapes the social world that we live in."
  },
  {
    "objectID": "index.html#course-texts",
    "href": "index.html#course-texts",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "Available as audiobooks (Audible) and ebooks (Kindle), as well as print.\nKyle Chayka, Filterworld: How Algorithms Flattened Culture. New York: Doubleday, 2024.\nKate Eichhorn, Content. Essential Knowledge Series. Cambridge, MA: MIT Press, 2022.\nParmy Olson, Supremacy: AI, ChatGPT, and the Race that Will Change the World. New York: MacMillan, 2024.\nChristine Lagorio-Chafkin, We Are the Nerds: The Birth and Tumultuous Life of Reddit, the Internet’s Culture Laboratory. New York: Hachette Books, 2018.\nAllissa V. Richardson, Bearing Witness While Black: African Americans, Smartphones, and the New Protest #Journalism. Oxford: Oxford University Press, 2020.\nStefania Maurizi, Secret Power: Wikileaks and Its Enemies. Pluto Press, 2023.\n\n\n\nCitizenfour (2014)\nRisk (2016)\nSuper Pumped: The Battle for Uber (Showtime, 2022)\nWe Are Legion: The Story of the Hacktivists (2012)\nWeWork: Or the Making and Breaking of a $47 Billion Unicorn (Hulu, 2021)\nWikileaks: Secrets and Lies (2011)"
  },
  {
    "objectID": "index.html#course-information",
    "href": "index.html#course-information",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "Platforms\nWe’ll be using Blackboard for submitting assignments ONLY. For discussion, we will be using Discord.\nOn Discord, if you don’t already have an account, please set one up using your Fitchburg State University email address as ID.\nIf you already have a Discord account there will be problems setting up an account for the course because each account has to be tied to a different phone number, so you will not be able to use your regular phone number for verification. For this reason, you may use your existing account, but if you use a pseudonym please let me know what this is so I know who you are!\nPlease be sure to check in to the site at least once daily M-F to check the Announcements page and the Discussion forum for the week."
  },
  {
    "objectID": "index.html#assignments-evaluation",
    "href": "index.html#assignments-evaluation",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "Review\n6, weekly from Week 1, one short post responding to readings, 250 words (maximum), due by Sunday of each week (20%)\nDiscord\nRegular participation in weekly discussion and other channels (20%)\nCommentary papers\n2 short analysis papers (500 words, 2 pages double-spaced) based on any of the reading assignments, due on Blackboard by end of Weeks 2 and 4 (Sunday) (20%)\nBook Report\nCritical review (1,000 words, 4 pages double-spaced) of any text from the select bibliography. You are expected to read at least one additional chapter from any of the main course books. For texts scheduled in weeks 5-6, you’ll need to read ahead. Due on Blackboard by Friday of Week 5 (20%)\nResearch paper/report/creative project  2,000 words, due on Blackboard by Friday of Week 7 (20%)\nThe culminating written assignment for the course (2,000 words) may consist of various formats: a research paper or report, or a creative project (blog, website, podcast)\nA 1-page tentative proposal with ideas for your project, with a short bibliography with sources and/or links, should be posted in the Discussion forum on Blackboard by the end of Week 3, and you will receive feedback during Week 4.\n\nBy Wednesday of each week, I will post an Agenda item in the Discussion forum for the topic of the week, that introduces and contextualizes the reading assignments for the week, identifying key themes, concepts, and/or issues to look out for as you read.\nCommentary Papers\nThese short papers (750-1,000 words) are due at the end of Week 2 and Week 4 (Sunday). They should consist of analytical close readings of any of the reading assignments for the period Weeks 1-2 or 3-4. You are encouraged to focus in detail on particular sections, arguments, and/or concepts from the readings and develop them.\nResearch Paper/Project\nThe culminating written assignment for the course (2,000 words) may consist of various formats: a research paper or report, or a creative project of your choice.\nA 1-page preliminary proposal with ideas for your project, with a short bibliography with sources and/or links, should be posted in the Discussion forum for the purpose by the end of Week 3, and you will receive feedback during Week 4."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "Week 1: Tuesday 29 October 2024\nContent\nKate Eichhorn, Content:\n\n“A Brief History of Content in a Digital Era”\n“User-Generated Content” (recommended)\n\nSee also: Patrick H. Willems, “Everything is Content Now” (YouTube)\n\nWeek 2: Tuesday 5 November 2024\nAlgorithm\nKyle Chayka, Filterworld: How Algorithms Flattened Culture\n\n“Introduction”\n“The Rise of Algorithmic Recommendations” (ch. 1)\n\n\nWeek 3: Tuesday 12 November 2024\nChatbot\nParmy Olson, Supremacy: How the Struggle Between Google and Facebook Shapes Our Future\n\n“Prologue”\n“Mythbusters” (ch. 12)\n“Hello, ChatGPT” (ch. 13)\n\n\nWeek 4: Tuesday 19 November 2024\nNerd\nChristine Lagorio-Chafkin, We Are the Nerds: The Birth and Tumultuous Life of Reddit, the Internet’s Culture Laboratory\n\nWeek 5: Tuesday 26 November 2024\nWitness\nAllissa V. Richardson, Bearing Witness While Black\n\nWeek 6: Tuesday 3 December 2024\nWhistleblower\nStefania Maurizi, Secret Power: Wikileaks and Its Enemies\n\nWeek 7: Tuesday 10 December 2024\nResearch projects\nTuesday 17 December 2024: Last day of classes"
  },
  {
    "objectID": "index.html#bibliography",
    "href": "index.html#bibliography",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "danah boyd, It’s Complicated: The Social Lives of Networked Teens (New Haven: Yale University Press, 2014).\nAmy Bruckman, Should You Believe Wikipedia? Online Communities and the Construction of Knowledge (Cambridge: Cambridge University Press, 2022).\nFinn Brunton and Helen Nissenbaum, Obfuscation: A User’s Guide for Privacy and Protest (Cambridge: MIT Press, 2016).\nKyle Chayka, Filterworld: How Algorithms Flattened Culture (New York: Doubleday, 2024).\nGabriella Coleman, Hacker, Hoaxer, Whistleblower, Spy: The Many Faces of Anonymous (London and New York: Verso, 2014).\nClaire Dederer, Monsters: A Fan’s Dilemma (New York: Alfred A. Knopf, 2023).\nKate Eichhorn, Content. Essential Knowledge Series (Cambridge, MA: MIT Press, 2022).\nGlenn Greenwald, No Place to Hide: Edward Snowden, the NSA, and the U.S. Surveillance State (New York: Metropolitan Books, 2014).\nAdrian Hon, You’ve Been Played: How Corporations, Governments, and Schools Use Games to Control Us All (New York: Basic Books, 2022).\nSarah J. Jackson, Moya Bailey, et al., #Hashtag Activism: Networks of Race and Gender Justice (Cambridge: MIT Press, 2020).\nChristine Lagorio-Chafkin, We Are the Nerds: The Birth and Tumultuous Life of Reddit, the Internet’s Culture Laboratory (New York: Hachette Books, 2018).\nTaylor Lorenz, Extremely Online: How the Internet Changed the Way We Live, Love, Work, and Play (New York: Simon & Schuster, 2022}.\nGary Marcus & Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust (New York: Pantheon Books, 2019).\nStefania Maurizi, Secret Power: Wikileaks and Its Enemies. Pluto Press, 2023.\nGretchen McCulloch, Because Internet: Understanding the New Rules of Language (Riverhead Books, 2019)\nAngela Nagle, Kill All Normies: Online Culture Wars From 4Chan and Tumblr to Trump and the Alt-Right (Alresford, Hampshire, UK: Zero Books, 2017).\nParmy Olson, Supremacy: AI, ChatGPT, and the Race that Will Change the World. New York: MacMillan, 2024.\nCathy O’Neil, with Stephen Baker, The Shame Machine: Who Profits in the New Age of Humiliation (New York: Crown/Random House, 2022).\nWhitney Phillips, This Is Why We Can’t Have Nice Things: Mapping the Relationship between Online Trolling and Mainstream Culture (Cambridge: MIT Press, 2015).\nWhitney Phillips and Ryan M. Milner, You Are Here: A Field Guide for Navigating Polarized Speech, Conspiracy Theories, and Our Polluted Media Landscape (Cambridge: MIT Press, 2021).\nAllissa V, Richardson, Bearing Witness While Black: African Americans, Smartphones, and the New Protest #Journalism (Oxford: Oxford University Press, 2020).\nZeynep Tufekci, Twitter and Tear Gas: The Power and Fragility of Networked Protes (New Haven: Yale University Press, 2017}.\nMichele White, Touch Screen Theory: Digital Devices and Feelings (Cambridge, MA: MIT Press, 2022).\nChristopher Wylie, Mindf**k: Cambridge Analytica and the Plot to Break America (New York: Random House, 2019)."
  },
  {
    "objectID": "index.html#policies",
    "href": "index.html#policies",
    "title": "COMM 7007: Social Mobilities",
    "section": "",
    "text": "Late Policy\nAssignments that are late will lose 1/2 of a grade per day, beginning at the end of class and including weekends and holidays. This means that a paper, which would have received an A if it was on time, will receive a B+ the next day, B- for two days late, and so on. Time management, preparation for our meetings, and timely submission of your work comprise a significant dimension of your professionalism. As such, your work must be completed by the beginning of class on the day it is due. If you have a serious problem that makes punctual submission impossible, you must discuss this matter with me before the due date so that we can make alternative arrangements. Because you are given plenty of time to complete your work, and major due dates are given to you well in advance, last minute problems should not preclude handing in assignments on time.\nMandatory Reporter\nFitchburg State University is committed to providing a safe learning environment for all students that is free of all forms of discrimination and harassment. Please be aware all FSU faculty members are “mandatory reporters,” which means that if you tell me about a situation involving sexual harassment, sexual assault, dating violence, domestic violence, or stalking, I am legally required to share that information with the Title IX Coordinator. If you or someone you know has been impacted by sexual harassment, sexual assault, dating or domestic violence, or stalking, FSU has staff members trained to support you. If you or someone you know has been impacted by sexual harassment, sexual assault, dating or domestic violence, or stalking, please visit http://fitchburgstate.edu/titleix to access information about university support and resources.\nHealth\nHealth Services\nHours: Monday-Friday 8:30AM-5PM Location: Ground Level of Russell Towers (across from the entrance of Holmes Dining Hall) Phone: (978) 665-3643/3894\nCounseling Services\nThe Counseling Services Office offers a range of services including individual, couples and group counseling, crisis intervention, psychoeducational programming, outreach ALTERNATIVE ECOSYSTEMSs, and community referrals. Counseling services are confidential and are offered at no charge to all enrolled students. Staff at Counseling Services are also available for consultation to faculty, staff and students. Counseling Services is located in the Hammond, 3rd Floor, Room 317.\nFitchburg Anti-Violence Education (FAVE)\nFAVE collaborates with a number of community partners (e.g., YWCA Domestic Violence Services, Pathways for Change) to meet our training needs and to link survivors with community based resources. This site also features resources for help or information about dating violence, domestic violence, sexual assault and stalking. If you or someone you know is in an abusive relationship or has been a victim of sexual assault, there are many places to go for help. Many can be accessed 24 hours a day, seven days a week, 365 days a year. On campus, free and confidential support is provided at both Counseling Services and Health Services.\nCommunity Food Pantry Food insecurity is a growing issue and it certainly can affect student learning. The ability to have access to nutritious food is incredibly vital. The Falcon Bazaar, located in Hammond G 15, is stocked with food, basic necessities, and can provide meal swipes to support all Fitchburg State students experiencing food insecurity for a day or a semester.\nThe university continues to partner with Our Father’s House to support student needs and access to food and services. All Fitchburg State University students are welcome at the Our Father’s House Community Food Pantry. This Pantry is located at the Faith Christian Church at 40 Boutelle St., Fitchburg, MA and is open from 5-7pm. Each “household” may shop for nutritious food once per month by presenting a valid FSU ID.\nAcademic Integrity\nThe University “Academic Integrity” policy can be found online at http:// www.fitchburgstate.edu/offices-services-directory/office-of-student-conductmediation-education/academic-integrity/. Students are expected to do their own work. Plagiarism and cheating are inexcusable. Any instance of plagiarism or cheating will automatically result in a zero on the assignment and may be reported the Office of Student and Academic Life at the discretion of the instructor.\nPlagiarism includes, but is not limited to: - Using papers or work from another class. - Using another student’s paper or work from any class. - Copying work or a paper from the Internet. - The egregious lack of citing sources or documenting research.\nIf you’re not clear on what is or is not plagiarism, ASK. The BEST case scenario if caught is a zero on that assignment, and ignorance of what does or does not count is not an excuse. That being said, I’m a strong supporter of Fair Use doctrine. Just attribute what you use–and, again, ASK if there’s any doubt.\nAmericans With Disabilities Act (ADA)\nIf you need course adaptations or accommodations because of a disability, if you have emergency medical information to share with the instructor, or if you need special arrangements in case the building must be evacuated, please inform the faculty member as soon as possible.\nTechnology\nAt some point during the semester you will likely have a problem with technology. Your laptop will crash; your iPad battery will die; a recording you make will disappear; you will accidentally delete a file; the wireless will go down at a crucial time. These, however, are inevitabilities of life, not emergences. Technology problems are not excuses for unfinished or late work. Bad things may happen, but you can protect yourself by doing the following:\n\nPlan ahead: A deadline is the last minute to turn in material. You can start—and finish—early, particularly if challenging resources are required, or you know it will be time consuming to finish this project.\nSave work early and often: Think how much work you do in 10 minutes. I auto save every 2 minutes.\nMake regular backups of files in a different location: Between Box, Google Drive, Dropbox, and iCloud, you have ample places to store and backup your materials. Use them.\nSave drafts: When editing, set aside the original and work with a copy.\nPractice safe computing: On your personal devices, install and use software to control viruses and malware.\n\nGrading Policy\nGrading for the course will follow the FSU grading policy below:\n4.0: 95-100\n3.7: 92-94\n3.5: 89-91\n3.3: 86-88\n3.0: 83-85\n2.7: 80-82\n2.5: 77-79\n2.3: 74-76\n2.0: 71-73\n0.0: &lt; 70\nAcademic Resources\nWriting Center\nAcademic Policies\nDisability Services\nFitchburg State Alert system for emergencies, snow closures/delays, and faculty absences\nUniversity Career Services"
  },
  {
    "objectID": "w3-chatbots.html",
    "href": "w3-chatbots.html",
    "title": "Home",
    "section": "",
    "text": "Imagine if a pharmaceutical company released a new drug with no clinical trials and said it was testing the medication on the wider public. Or a food company released an experimental preservative with little scrutiny. That was how large tech firms were about to start deploying large language models to the public, because in their race to profit from such powerful tools, there were zero regulatory standards to follow. It was up to the safety and ethics researchers to study all the risks from inside these firms, but they were hardly a force to be reckoned with. At Google, their leaders had been fired. At DeepMind, they represented a tiny proportion of the research team. A signal was emerging more clearly each day. Get on board with the mission to build something bigger, or leave. Parmy Olson, Supremacy: How the Struggle Between Google and Facebook Shapes Our Future, ch. 12.\n\nReading Parmy Olson’s account of Microsoft’s AI coding assistant, GitHub Copilot, at the start of chapter 13 of her book about ChatGPT, I couldn’t help but smile. I’m writing this post in Visual Studio, the IDE (Integrated Development Environment) that as Olson mentions, was the app used by coders in which GitHub Copilot was first implemented. Not being a programmer, I only started using Copilot this past summer, but I haven’t looked back. Not only does the current version predictively suggest code, as Olson explains, it also suggests textual content as you’re actually writing. It also isn’t limited to Visual Studio—I also use it as a plugin for RStudio, the IDE that I use for web authoring. After enabling it last summer, when I started authoring posts I was shocked to discover it literally trying to finish my sentences—all I needed to do was hit TAB to accept the suggestion and a whole paragraph describing, for example, a videogame, would appear before my eyes. My initial instinct was to disable it, but I quickly realized that the rather generic overview that I’d been starting to write, and that the AI had auto-suggested to me, wasn’t all that bad, with some editing. I could certainly use this sentence, and maybe this one…\nI even used GitHub Copilot as an assistant while authoring the syllabus for this course—not to suggest reading assignments, but simply to complete citations for sources I was planning to use (in the bibliography, etc.) without having to type them out in full. What I also quickly noticed, however, was that the citations that were magically appearing before my eyes were frequently wrong, in terms of the information about sources that they were providing, even though they were impeccably formatted. This actually created more work as I realized that I had to fact-check every citation that Copilot was generating, apparently out of thin air.\nSo this is the dilemma that we all now increasingly find ourselves in. The fox is definitively in the henhouse (or whatever the metaphor is–Trojan Horse? Nah, it’s already been used), and there seems no likelihood of ejecting it anytime soon. In many ways, indeed, the fox’s presence not only seems not all that bad but has the potential to save us countless hours that had previously been spent on repetitive, time-consuming tasks. Aware of it or not, we are already using AI every day, whether in textual authoring (Grammerly), image processing (everything Adobe), or music DAWs (Ableton Live). AI is already on our laptops, our tablets, and our mobile devices.\nSince our course is focused specifically on mobile, handheld technologies and their relation to social media, while reading Parmy Olson’s book I’ve been thinking specifically about current implementations of AI on mobile devices. The recent launch of Apple’s own AI funcionality, Apple Intelligence—tagged “AI for the rest of us”—is a case in point, although since it isn’t supported either on my relatively ancient 2016 Macbook or my iPhone 13 Mini, I’m not going to be able to try it out until I upgrade to the more recent models that support it.\nBut by now, Apple Intelligence itself is rather late to the party: type “ChatGPT” as a search term into the App Store and you will be presented with literally dozens of chatbot apps, all promising AI-enhanced search. I encourage you to do this. Look more closely, though, and you’ll see that a large proportion of these apps announce themselves as powered by a relatively small number of the LLMs (Large Language Models) discussed in Olson’s book: OpenAI’s ChatGPT, Anthropic’s Claude, Google’s Gemini, DALL-E 2, Stable Diffusion, or Midjourney. In other words, the apps are basically just front-end interfaces to the models, acting as middelmen between us and them via the magic of APIs - essentially the code that runs much of the internet these days, that enables apps to share data between themselves.\nSo my first question this week would be about your own use—if any— of AI tools on your cellphones or tablets: do you now routinely use generative AI and/or any of this new generation of research tools in your everyday life? If so, which ones? How have you been using them, and what has been your experience so far? Have you encountered any of the problems that I mentioned earlier, about generative AI auto-suggesting incorrect information, or ChatGPT (or some other tool) returning random answers that have become known as hallucinations?\nParallel to the generative AI revolution itself, over the past five years there has been an explosion in both academic and popular books about the revolution itself and its wider implications across all dimensions of 21C society, whether ethical, political, economic, social, cultural, or aesthetic. Obviously we don’t have time to explore all of these dimensions here, but personally I have been especially interested in exploring the cultural and aesthetic implications of generative AI. In this course, I wanted to assign to you some of the most interesting texts I’ve come across in this area in recent years, as well as some of the most recent and up-to-date ones: when the field itself seems to be transforming from one day to the next, before our very eyes, it’s particularly important to keep up with current developments, whether in publications or online platforms such as Medium or Substack. So part of what I wanted to do this week is simply to share with you some of the resources that I’ve found most informative and though-provoking in recent years on the much-debated topic of generative AI.\nChapter 12 of Parmy Olson’s book is useful in laying out some of the background of the current debates around generative AI. In particular, I wanted you to read about Emily Bender’s (et al.) influential Stochastic Parrots co-written article, which I’m linking to here. The article itself, although quite short, is an academic paper and therefore quite technical. It’s important to know about and worth taking a look at, but a more user-friendly introduction is this interview with Emily Bender herself in New York magazine.\nAs you’ll have seen, the title of Olson’s chapter is “Mythbusters.” A lot of the myth-busting around generative AI has been coming from linguists like Emily Bender, who have sought to debunk many of the wild and frequently dystopian claims about AI surpassing human-level intelligence, or even achieving consciousness (aka “sentience”) in the case of ex-Google employee Blake Lemoine. As Gary Marcus and Ernest Jones put it in a chapter of their co-authored book Rebooting AI “If Computers Are So Smart, Why Can’t They Read?” (also linked here). As the authors demonstrate in the chapter, even the most state-of-the-art AI today is not even capable of actually understanding a simple children’s story in any meaningful human sense; it is only capable of extrapolating explicit information by pattern matching strings of words. Depending on the context, this may be a very useful affordance, but it is not even close to the richness of human understanding, which depends on something called inferential meanings. Marcus and Jones explain all this brilliantly in the chapter and I strongly encourage you to read it. The rest of their book is devoted to explaining what it would take for us to be able to design a genuine form of artificial intelligence, but as they argue in the book, this is somthing that is unlikely to happen in the near or even more distant future. Instead, we will have more convincing versions of what we have now: simulations of intelligence, and chatbots that can pass as human under very restricted conditions.Gary Marcus & Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust (New York: Pantheon Books, 2019).\nAnother source of critique of generative AI centers on identity and inclusivity, involving “bias” and assymetries in the representation particularly of women and minority identities in generative AI outputs–itself the result of insufficient inclusivity in the datasets on which LLMs are modeled. This in itself is a large area of debate. If you’re interested in exploring this aspect of generative AI further, a useful documentary to watch is Coded Bias (Shalini Kantayya, 2020), available on Netflix.\nSince this post is already too long, I’ll finish by just including some links to useful (human-authored) sources for further exploration of the subject of generative AI in relation to social media and mobile technologies. Feel free to message me if you have any questions, if you’d like further recommendations, or you just want to chat about the subject!\nLooking forward to this week’s discussion on Discord!\nSources (referenced in chs. 12-13 of Parmy Olson’s book Supremacy)\nParmy Olson, “My Girlfriend is a Chatbot” (Wall Street Journal, 10 April 2020).\nTom Simonite, “What Really Happened When Google Ousted Timnit Gebru” (WIRED, 8 June 2021).",
    "crumbs": [
      "Agendas",
      "W3 Chatbots"
    ]
  },
  {
    "objectID": "w3-chatbots.html#w3-prediction-machines-chatbots-generative-ai",
    "href": "w3-chatbots.html#w3-prediction-machines-chatbots-generative-ai",
    "title": "Home",
    "section": "",
    "text": "Imagine if a pharmaceutical company released a new drug with no clinical trials and said it was testing the medication on the wider public. Or a food company released an experimental preservative with little scrutiny. That was how large tech firms were about to start deploying large language models to the public, because in their race to profit from such powerful tools, there were zero regulatory standards to follow. It was up to the safety and ethics researchers to study all the risks from inside these firms, but they were hardly a force to be reckoned with. At Google, their leaders had been fired. At DeepMind, they represented a tiny proportion of the research team. A signal was emerging more clearly each day. Get on board with the mission to build something bigger, or leave. Parmy Olson, Supremacy: How the Struggle Between Google and Facebook Shapes Our Future, ch. 12.\n\nReading Parmy Olson’s account of Microsoft’s AI coding assistant, GitHub Copilot, at the start of chapter 13 of her book about ChatGPT, I couldn’t help but smile. I’m writing this post in Visual Studio, the IDE (Integrated Development Environment) that as Olson mentions, was the app used by coders in which GitHub Copilot was first implemented. Not being a programmer, I only started using Copilot this past summer, but I haven’t looked back. Not only does the current version predictively suggest code, as Olson explains, it also suggests textual content as you’re actually writing. It also isn’t limited to Visual Studio—I also use it as a plugin for RStudio, the IDE that I use for web authoring. After enabling it last summer, when I started authoring posts I was shocked to discover it literally trying to finish my sentences—all I needed to do was hit TAB to accept the suggestion and a whole paragraph describing, for example, a videogame, would appear before my eyes. My initial instinct was to disable it, but I quickly realized that the rather generic overview that I’d been starting to write, and that the AI had auto-suggested to me, wasn’t all that bad, with some editing. I could certainly use this sentence, and maybe this one…\nI even used GitHub Copilot as an assistant while authoring the syllabus for this course—not to suggest reading assignments, but simply to complete citations for sources I was planning to use (in the bibliography, etc.) without having to type them out in full. What I also quickly noticed, however, was that the citations that were magically appearing before my eyes were frequently wrong, in terms of the information about sources that they were providing, even though they were impeccably formatted. This actually created more work as I realized that I had to fact-check every citation that Copilot was generating, apparently out of thin air.\nSo this is the dilemma that we all now increasingly find ourselves in. The fox is definitively in the henhouse (or whatever the metaphor is–Trojan Horse? Nah, it’s already been used), and there seems no likelihood of ejecting it anytime soon. In many ways, indeed, the fox’s presence not only seems not all that bad but has the potential to save us countless hours that had previously been spent on repetitive, time-consuming tasks. Aware of it or not, we are already using AI every day, whether in textual authoring (Grammerly), image processing (everything Adobe), or music DAWs (Ableton Live). AI is already on our laptops, our tablets, and our mobile devices.\nSince our course is focused specifically on mobile, handheld technologies and their relation to social media, while reading Parmy Olson’s book I’ve been thinking specifically about current implementations of AI on mobile devices. The recent launch of Apple’s own AI funcionality, Apple Intelligence—tagged “AI for the rest of us”—is a case in point, although since it isn’t supported either on my relatively ancient 2016 Macbook or my iPhone 13 Mini, I’m not going to be able to try it out until I upgrade to the more recent models that support it.\nBut by now, Apple Intelligence itself is rather late to the party: type “ChatGPT” as a search term into the App Store and you will be presented with literally dozens of chatbot apps, all promising AI-enhanced search. I encourage you to do this. Look more closely, though, and you’ll see that a large proportion of these apps announce themselves as powered by a relatively small number of the LLMs (Large Language Models) discussed in Olson’s book: OpenAI’s ChatGPT, Anthropic’s Claude, Google’s Gemini, DALL-E 2, Stable Diffusion, or Midjourney. In other words, the apps are basically just front-end interfaces to the models, acting as middelmen between us and them via the magic of APIs - essentially the code that runs much of the internet these days, that enables apps to share data between themselves.\nSo my first question this week would be about your own use—if any— of AI tools on your cellphones or tablets: do you now routinely use generative AI and/or any of this new generation of research tools in your everyday life? If so, which ones? How have you been using them, and what has been your experience so far? Have you encountered any of the problems that I mentioned earlier, about generative AI auto-suggesting incorrect information, or ChatGPT (or some other tool) returning random answers that have become known as hallucinations?\nParallel to the generative AI revolution itself, over the past five years there has been an explosion in both academic and popular books about the revolution itself and its wider implications across all dimensions of 21C society, whether ethical, political, economic, social, cultural, or aesthetic. Obviously we don’t have time to explore all of these dimensions here, but personally I have been especially interested in exploring the cultural and aesthetic implications of generative AI. In this course, I wanted to assign to you some of the most interesting texts I’ve come across in this area in recent years, as well as some of the most recent and up-to-date ones: when the field itself seems to be transforming from one day to the next, before our very eyes, it’s particularly important to keep up with current developments, whether in publications or online platforms such as Medium or Substack. So part of what I wanted to do this week is simply to share with you some of the resources that I’ve found most informative and though-provoking in recent years on the much-debated topic of generative AI.\nChapter 12 of Parmy Olson’s book is useful in laying out some of the background of the current debates around generative AI. In particular, I wanted you to read about Emily Bender’s (et al.) influential Stochastic Parrots co-written article, which I’m linking to here. The article itself, although quite short, is an academic paper and therefore quite technical. It’s important to know about and worth taking a look at, but a more user-friendly introduction is this interview with Emily Bender herself in New York magazine.\nAs you’ll have seen, the title of Olson’s chapter is “Mythbusters.” A lot of the myth-busting around generative AI has been coming from linguists like Emily Bender, who have sought to debunk many of the wild and frequently dystopian claims about AI surpassing human-level intelligence, or even achieving consciousness (aka “sentience”) in the case of ex-Google employee Blake Lemoine. As Gary Marcus and Ernest Jones put it in a chapter of their co-authored book Rebooting AI “If Computers Are So Smart, Why Can’t They Read?” (also linked here). As the authors demonstrate in the chapter, even the most state-of-the-art AI today is not even capable of actually understanding a simple children’s story in any meaningful human sense; it is only capable of extrapolating explicit information by pattern matching strings of words. Depending on the context, this may be a very useful affordance, but it is not even close to the richness of human understanding, which depends on something called inferential meanings. Marcus and Jones explain all this brilliantly in the chapter and I strongly encourage you to read it. The rest of their book is devoted to explaining what it would take for us to be able to design a genuine form of artificial intelligence, but as they argue in the book, this is somthing that is unlikely to happen in the near or even more distant future. Instead, we will have more convincing versions of what we have now: simulations of intelligence, and chatbots that can pass as human under very restricted conditions.Gary Marcus & Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust (New York: Pantheon Books, 2019).\nAnother source of critique of generative AI centers on identity and inclusivity, involving “bias” and assymetries in the representation particularly of women and minority identities in generative AI outputs–itself the result of insufficient inclusivity in the datasets on which LLMs are modeled. This in itself is a large area of debate. If you’re interested in exploring this aspect of generative AI further, a useful documentary to watch is Coded Bias (Shalini Kantayya, 2020), available on Netflix.\nSince this post is already too long, I’ll finish by just including some links to useful (human-authored) sources for further exploration of the subject of generative AI in relation to social media and mobile technologies. Feel free to message me if you have any questions, if you’d like further recommendations, or you just want to chat about the subject!\nLooking forward to this week’s discussion on Discord!\nSources (referenced in chs. 12-13 of Parmy Olson’s book Supremacy)\nParmy Olson, “My Girlfriend is a Chatbot” (Wall Street Journal, 10 April 2020).\nTom Simonite, “What Really Happened When Google Ousted Timnit Gebru” (WIRED, 8 June 2021).",
    "crumbs": [
      "Agendas",
      "W3 Chatbots"
    ]
  }
]